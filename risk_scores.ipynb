{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9824264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import re, sys, time, json, warnings\n",
    "from datetime import datetime, timezone\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.preprocessing import RobustScaler, MaxAbsScaler\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"COVALENT_API_KEY\")\n",
    "CHAIN_ID  = \"1\"                          \n",
    "PAGE_SIZE = 100\n",
    "RATE_WAIT = 0.15                         \n",
    "WALLETS_CSV = \"wallets.csv\"\n",
    "\n",
    "TOKENLIST_URL = \"https://raw.githubusercontent.com/compound-finance/token-list/master/compound.tokenlist.json\"\n",
    "\n",
    "EVENT_MAP = {\n",
    "    \"mint\": \"supply\",       \"supply\": \"withdraw\",   \"withdraw\": \"withdraw\",\n",
    "    \"borrow\": \"borrow\",\n",
    "    \"repayborrow\": \"repay\", \"repay\": \"repay\",\n",
    "    \"liquidateborrow\": \"liquidate\", \"absorb\": \"liquidate\",\n",
    "}\n",
    "\n",
    "FEATURE_WEIGHTS = {\n",
    "    \"borrow_supply_ratio\": 25.0,\n",
    "    \"liquidation_cnt\": 20.0,\n",
    "    \"total_liquidated_usd\": 18.0,\n",
    "    \"net_borrowed_usd\": 15.0,\n",
    "    \"days_since_last_interaction\": 12.0,\n",
    "    \"max_single_action_usd\": 10.0,\n",
    "    \"compound_risk_flag\": 8.0,\n",
    "    \"exposure_tier\": 7.0,\n",
    "    \"repayment_ratio\": -10.0,\n",
    "    \"total_supplied_usd\": -8.0,\n",
    "    \"account_age_days\": -6.0,\n",
    "    \"interaction_frequency\": -5.0,\n",
    "}\n",
    "\n",
    "ALL_FEATURES = [\n",
    "    \"total_supplied_usd\", \"total_borrowed_usd\", \"total_repaid_usd\", \n",
    "    \"total_liquidated_usd\", \"liquidation_cnt\", \"borrow_supply_ratio\",\n",
    "    \"repayment_ratio\", \"net_borrowed_usd\", \"account_age_days\",\n",
    "    \"days_since_last_interaction\", \"max_single_action_usd\", \n",
    "    \"interaction_frequency\", \"compound_risk_flag\", \"exposure_tier\"\n",
    "]\n",
    "\n",
    "ETH_RE = re.compile(r\"^0x[a-fA-F0-9]{40}$\")\n",
    "\n",
    "def is_eth(addr: str) -> bool:\n",
    "    return isinstance(addr, str) and bool(ETH_RE.match(addr.strip()))\n",
    "\n",
    "def load_wallets(csv_path=WALLETS_CSV):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path, header=None)\n",
    "        col = df.iloc[:, 0].astype(str).str.strip()\n",
    "        \n",
    "        if not is_eth(col.iloc[0]):\n",
    "            col = col.iloc[1:]\n",
    "        \n",
    "        wallets = col[col.apply(is_eth)].str.lower().unique().tolist()\n",
    "        \n",
    "        if not wallets:\n",
    "            sys.exit(\"No valid Ethereum addresses found in wallets.csv\")\n",
    "        \n",
    "        return wallets\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        sys.exit(f\"File '{csv_path}' not found\")\n",
    "    except Exception as e:\n",
    "        sys.exit(f\"Error reading wallets.csv: {e}\")\n",
    "\n",
    "def refresh_compound_contracts():\n",
    "    try:\n",
    "        response = requests.get(TOKENLIST_URL, timeout=20)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        tokens = response.json()[\"tokens\"]\n",
    "        ethereum_tokens = [t for t in tokens if t[\"chainId\"] == 1]\n",
    "        addresses = {t[\"address\"].lower() for t in ethereum_tokens}\n",
    "        \n",
    "        addresses.update({\n",
    "            \"0x3d9819210a31b4961b30ef54be2aed79b9c9cd3b\",  # Comptroller\n",
    "            \"0xc00e94cb662c3520282e6f5717214004a7f26888\",  # COMP token\n",
    "        })\n",
    "        \n",
    "        return addresses\n",
    "        \n",
    "    except Exception:\n",
    "        return {\n",
    "            \"0x3d9819210a31b4961b30ef54be2aed79b9c9cd3b\",  # Comptroller\n",
    "            \"0xc00e94cb662c3520282e6f5717214004a7f26888\",  # COMP\n",
    "            \"0x4ddc2d193948926d02f9b1fe9e1daa0718270ed5\",  # cETH\n",
    "            \"0x5d3a536e4d6dbd6114cc1ead35777bab948e3643\",  # cDAI\n",
    "            \"0x39aa39c021dfbae8fac545936693ac917d5e7563\",  # cUSDC\n",
    "            \"0x6c8c6b02e7b2be14d4fa6022dfd6dbe0a5d3d6d3\",  # cBAT\n",
    "            \"0xf5dce57282a584d2746faf1593d3121fcac444dc\",  # cUSDT\n",
    "        }\n",
    "\n",
    "COMPOUND_CONTRACTS = refresh_compound_contracts()\n",
    "\n",
    "def fetch_all_transactions(wallet: str):\n",
    "    transactions, page = [], 0\n",
    "    max_retries = 3\n",
    "    \n",
    "    while True:\n",
    "        url = f\"https://api.covalenthq.com/v1/{CHAIN_ID}/address/{wallet}/transactions_v2/\"\n",
    "        params = {\"key\": API_KEY, \"page-size\": PAGE_SIZE, \"page-number\": page}\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = requests.get(url, params=params, timeout=30)\n",
    "                response.raise_for_status()\n",
    "                \n",
    "                data = response.json()\n",
    "                if not data or \"data\" not in data:\n",
    "                    return transactions\n",
    "                    \n",
    "                items = data[\"data\"].get(\"items\", [])\n",
    "                break\n",
    "                \n",
    "            except requests.RequestException:\n",
    "                if attempt == max_retries - 1:\n",
    "                    return transactions\n",
    "                time.sleep(2 ** attempt)\n",
    "        else:\n",
    "            return transactions\n",
    "            \n",
    "        if not items:\n",
    "            break\n",
    "            \n",
    "        transactions.extend(items)\n",
    "        if len(items) < PAGE_SIZE:\n",
    "            break\n",
    "            \n",
    "        page += 1\n",
    "        time.sleep(RATE_WAIT)\n",
    "        \n",
    "    return transactions\n",
    "\n",
    "def safe_float(value, default=0.0):\n",
    "    try:\n",
    "        return float(value) if value is not None else default\n",
    "    except (ValueError, TypeError):\n",
    "        return default\n",
    "\n",
    "def safe_get_params(decoded_event):\n",
    "    if not isinstance(decoded_event, dict):\n",
    "        return []\n",
    "    \n",
    "    params = decoded_event.get(\"params\")\n",
    "    if params is None or not isinstance(params, list):\n",
    "        return []\n",
    "    \n",
    "    return params\n",
    "\n",
    "def extract_wallet_features(wallet: str, transactions: list) -> dict:\n",
    "    features = {feature: 0.0 for feature in ALL_FEATURES}\n",
    "    features[\"wallet_id\"] = wallet\n",
    "    \n",
    "    if not transactions:\n",
    "        return features\n",
    "    \n",
    "    now_timestamp = datetime.now(timezone.utc).timestamp()\n",
    "    timestamps, usd_values = [], []\n",
    "    \n",
    "    try:\n",
    "        for tx in transactions:\n",
    "            to_address = (tx.get(\"to_address\") or \"\").lower()\n",
    "            log_events = tx.get(\"log_events\", [])\n",
    "            \n",
    "            is_compound_tx = (\n",
    "                to_address in COMPOUND_CONTRACTS or\n",
    "                any((event.get(\"sender_address\") or \"\").lower() in COMPOUND_CONTRACTS\n",
    "                    for event in log_events if isinstance(event, dict))\n",
    "            )\n",
    "            \n",
    "            if not is_compound_tx:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                tx_timestamp = pd.to_datetime(tx[\"block_signed_at\"]).timestamp()\n",
    "                timestamps.append(tx_timestamp)\n",
    "            except (KeyError, TypeError, ValueError):\n",
    "                continue\n",
    "            \n",
    "            for event in log_events:\n",
    "                if not isinstance(event, dict):\n",
    "                    continue\n",
    "                \n",
    "                sender = (event.get(\"sender_address\") or \"\").lower()\n",
    "                if sender not in COMPOUND_CONTRACTS:\n",
    "                    continue\n",
    "                \n",
    "                decoded = event.get(\"decoded\")\n",
    "                if not isinstance(decoded, dict):\n",
    "                    continue\n",
    "                \n",
    "                event_name = decoded.get(\"name\", \"\").lower()\n",
    "                action_type = EVENT_MAP.get(event_name)\n",
    "                if not action_type:\n",
    "                    continue\n",
    "                \n",
    "                usd_value = safe_float(event.get(\"value_quote\"))\n",
    "                \n",
    "                if usd_value == 0:\n",
    "                    params = safe_get_params(decoded)\n",
    "                    for param in params:\n",
    "                        if not isinstance(param, dict):\n",
    "                            continue\n",
    "                        param_name = param.get(\"name\", \"\").lower()\n",
    "                        if param_name in (\"amount\", \"seizetokens\", \"borrowamount\", \"repayamount\"):\n",
    "                            usd_value = safe_float(param.get(\"value_quote\"))\n",
    "                            if usd_value > 0:\n",
    "                                break\n",
    "                \n",
    "                usd_values.append(usd_value)\n",
    "                \n",
    "                if action_type == \"supply\":\n",
    "                    features[\"total_supplied_usd\"] += usd_value\n",
    "                elif action_type == \"borrow\":\n",
    "                    features[\"total_borrowed_usd\"] += usd_value\n",
    "                    features[\"max_single_action_usd\"] = max(\n",
    "                        features[\"max_single_action_usd\"], usd_value\n",
    "                    )\n",
    "                elif action_type == \"repay\":\n",
    "                    features[\"total_repaid_usd\"] += usd_value\n",
    "                elif action_type == \"liquidate\":\n",
    "                    features[\"total_liquidated_usd\"] += usd_value\n",
    "                    features[\"liquidation_cnt\"] += 1\n",
    "        \n",
    "        if not timestamps:\n",
    "            return features\n",
    "        \n",
    "        first_timestamp = min(timestamps)\n",
    "        last_timestamp = max(timestamps)\n",
    "        \n",
    "        features[\"account_age_days\"] = (now_timestamp - first_timestamp) / 86400\n",
    "        features[\"days_since_last_interaction\"] = (now_timestamp - last_timestamp) / 86400\n",
    "        features[\"interaction_frequency\"] = len(timestamps) / max(features[\"account_age_days\"], 1)\n",
    "        \n",
    "        features[\"borrow_supply_ratio\"] = (\n",
    "            features[\"total_borrowed_usd\"] / (features[\"total_supplied_usd\"] + 1e-9)\n",
    "        )\n",
    "        features[\"repayment_ratio\"] = (\n",
    "            features[\"total_repaid_usd\"] / (features[\"total_borrowed_usd\"] + 1e-9)\n",
    "        )\n",
    "        features[\"net_borrowed_usd\"] = max(0, \n",
    "            features[\"total_borrowed_usd\"] - features[\"total_repaid_usd\"]\n",
    "        )\n",
    "        \n",
    "        features[\"compound_risk_flag\"] = (\n",
    "            (features[\"liquidation_cnt\"] > 0) * 3 +\n",
    "            (features[\"borrow_supply_ratio\"] > 0.8) * 2 +\n",
    "            (features[\"repayment_ratio\"] < 0.5) * 2 +\n",
    "            (features[\"days_since_last_interaction\"] > 365) * 1\n",
    "        )\n",
    "        \n",
    "        log_borrowed = np.log1p(features[\"total_borrowed_usd\"])\n",
    "        if log_borrowed > 15:\n",
    "            features[\"exposure_tier\"] = 4\n",
    "        elif log_borrowed > 10:\n",
    "            features[\"exposure_tier\"] = 3\n",
    "        elif log_borrowed > 5:\n",
    "            features[\"exposure_tier\"] = 2\n",
    "        elif log_borrowed > 0:\n",
    "            features[\"exposure_tier\"] = 1\n",
    "        else:\n",
    "            features[\"exposure_tier\"] = 0\n",
    "        \n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    return features\n",
    "\n",
    "def advanced_feature_scaling(dataframe):\n",
    "    scaled_df = dataframe.copy()\n",
    "    \n",
    "    usd_features = [\n",
    "        \"total_supplied_usd\", \"total_borrowed_usd\", \"total_liquidated_usd\", \n",
    "        \"net_borrowed_usd\", \"max_single_action_usd\"\n",
    "    ]\n",
    "    \n",
    "    for feature in usd_features:\n",
    "        if feature in dataframe.columns and dataframe[feature].sum() > 0:\n",
    "            log_values = np.log1p(dataframe[feature])\n",
    "            scaler = RobustScaler()\n",
    "            scaled_values = scaler.fit_transform(log_values.values.reshape(-1, 1)).flatten()\n",
    "            scaled_df[f\"{feature}_scaled\"] = np.clip(scaled_values * 20 + 50, 0, 100)\n",
    "        else:\n",
    "            scaled_df[f\"{feature}_scaled\"] = 0\n",
    "    \n",
    "    count_features = [\"liquidation_cnt\"]\n",
    "    for feature in count_features:\n",
    "        if feature in dataframe.columns and dataframe[feature].sum() > 0:\n",
    "            scaler = MaxAbsScaler()\n",
    "            scaled_values = scaler.fit_transform(dataframe[feature].values.reshape(-1, 1)).flatten()\n",
    "            scaled_df[f\"{feature}_scaled\"] = scaled_values * 100\n",
    "        else:\n",
    "            scaled_df[f\"{feature}_scaled\"] = 0\n",
    "    \n",
    "    ratio_features = [\"borrow_supply_ratio\", \"repayment_ratio\"]\n",
    "    for feature in ratio_features:\n",
    "        if feature in dataframe.columns:\n",
    "            scaled_df[f\"{feature}_scaled\"] = dataframe[feature].rank(pct=True) * 100\n",
    "        else:\n",
    "            scaled_df[f\"{feature}_scaled\"] = 0\n",
    "    \n",
    "    time_features = [\"account_age_days\", \"days_since_last_interaction\", \"interaction_frequency\"]\n",
    "    for feature in time_features:\n",
    "        if feature in dataframe.columns and dataframe[feature].sum() > 0:\n",
    "            scaler = RobustScaler()\n",
    "            scaled_values = scaler.fit_transform(dataframe[feature].values.reshape(-1, 1)).flatten()\n",
    "            scaled_df[f\"{feature}_scaled\"] = np.clip(scaled_values * 20 + 50, 0, 100)\n",
    "        else:\n",
    "            scaled_df[f\"{feature}_scaled\"] = 0\n",
    "    \n",
    "    composite_features = [\"compound_risk_flag\", \"exposure_tier\"]\n",
    "    for feature in composite_features:\n",
    "        if feature in dataframe.columns:\n",
    "            max_value = dataframe[feature].max()\n",
    "            if max_value > 0:\n",
    "                scaled_df[f\"{feature}_scaled\"] = (dataframe[feature] / max_value) * 100\n",
    "            else:\n",
    "                scaled_df[f\"{feature}_scaled\"] = 0\n",
    "        else:\n",
    "            scaled_df[f\"{feature}_scaled\"] = 0\n",
    "    \n",
    "    return scaled_df\n",
    "\n",
    "def calculate_risk_scores(raw_dataframe):\n",
    "    scaled_df = advanced_feature_scaling(raw_dataframe)\n",
    "    \n",
    "    total_scores = np.zeros(len(raw_dataframe))\n",
    "    \n",
    "    for feature, weight in FEATURE_WEIGHTS.items():\n",
    "        scaled_feature = f\"{feature}_scaled\"\n",
    "        if scaled_feature in scaled_df.columns:\n",
    "            contribution = scaled_df[scaled_feature] * (weight / 10)\n",
    "            total_scores += contribution\n",
    "    \n",
    "    if total_scores.max() > total_scores.min():\n",
    "        min_score = total_scores.min()\n",
    "        max_score = total_scores.max()\n",
    "        normalized_scores = (total_scores - min_score) / (max_score - min_score)\n",
    "        final_scores = (normalized_scores * 1000).round().astype(int)\n",
    "    else:\n",
    "        final_scores = np.zeros(len(raw_dataframe), dtype=int)\n",
    "    \n",
    "    risk_boost = (\n",
    "        (raw_dataframe[\"liquidation_cnt\"] > 0) * 150 +\n",
    "        (raw_dataframe[\"borrow_supply_ratio\"] > 0.7) * 100 +\n",
    "        (raw_dataframe[\"total_liquidated_usd\"] > 0) * 125 +\n",
    "        (raw_dataframe[\"compound_risk_flag\"] > 5) * 75\n",
    "    ).clip(0, 300)\n",
    "    \n",
    "    final_scores = np.maximum(final_scores, risk_boost).clip(0, 1000)\n",
    "    \n",
    "    return final_scores\n",
    "\n",
    "def main():\n",
    "    wallet_addresses = load_wallets()\n",
    "    \n",
    "    wallet_features = []\n",
    "    \n",
    "    for wallet in wallet_addresses:\n",
    "        try:\n",
    "            transactions = fetch_all_transactions(wallet)\n",
    "            features = extract_wallet_features(wallet, transactions)\n",
    "            wallet_features.append(features)\n",
    "        except Exception:\n",
    "            default_features = {feature: 0.0 for feature in ALL_FEATURES}\n",
    "            default_features[\"wallet_id\"] = wallet\n",
    "            wallet_features.append(default_features)\n",
    "    \n",
    "    raw_df = pd.DataFrame(wallet_features).fillna(0)\n",
    "    risk_scores = calculate_risk_scores(raw_df)\n",
    "    \n",
    "    results_df = pd.DataFrame({\n",
    "        \"wallet_id\": raw_df[\"wallet_id\"],\n",
    "        \"score\": risk_scores\n",
    "    })\n",
    "    \n",
    "    results_df.to_csv(\"risk_scores.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
